{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project\n",
    "## Predicting Ames Houses on the Entire Feature Set\n",
    "\n",
    "The ultimate goal of this project is to predict how much a house should be solved in Ames, IA.\n",
    "The problem is a standing [Kaggle Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). The dataset contains a list of information for all houses sold in Ames, Iowa from 2006 through 2010. It contains **2930** observations and a large number of explanatory\n",
    "variables (**23 nominal, 23 ordinal, 14 discrete, and 20 continuous**). Dean De Cook compiled and published this dataset in 2011 and can be found here [here](http://www.amstat.org/publications/jse/v19n3/decock.pdf). \n",
    "\n",
    "With the entry Id removed, the dataset is described by 304 features, after transformation of the categoricals to dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I . Import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5) \n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Pretty display for notebooks\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.gridspec as grd\n",
    "import matplotlib.ticker as tkr\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#define plotter\n",
    "minorLocatorx   = AutoMinorLocator(10)\n",
    "minorLocatory   = AutoMinorLocator(4)\n",
    "matplotlib.rc('xtick', labelsize=16) \n",
    "matplotlib.rc('ytick', labelsize=16) \n",
    "matplotlib.rcParams['axes.linewidth'] = 2.\n",
    "plt.rcParams['axes.linewidth'] = 4\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', serif='Times New Roman') \n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 9\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Load the dataset and drop the unnecessary sample ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ames housing dataset has 1460 data points with 80 variables each.\n",
      "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
      "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
      "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
      "\n",
      "     LandContour Utilities LotConfig    ...     PoolArea PoolQC  Fence  \\\n",
      "1457         Lvl    AllPub    Inside    ...            0    NaN  GdPrv   \n",
      "1458         Lvl    AllPub    Inside    ...            0    NaN    NaN   \n",
      "1459         Lvl    AllPub    Inside    ...            0    NaN    NaN   \n",
      "\n",
      "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "1457        Shed    2500      5    2010        WD         Normal     266500  \n",
      "1458         NaN       0      4    2010        WD         Normal     142125  \n",
      "1459         NaN       0      6    2008        WD         Normal     147500  \n",
      "\n",
      "[3 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the Ames housing dataset. This will have to be split for evaluation!\n",
    "data = pd.read_csv('train.csv')\n",
    "data = data.drop(['Id'], axis=1)\n",
    "# Success\n",
    "print \"Ames housing dataset has {} data points with {} variables each.\".format(*data.shape)\n",
    "print data.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Define training and preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions for creating sets and training.\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score\n",
    "\n",
    "############################################## Create Train/Test Splits ##############################################\n",
    "############################################## Create Train/Test Splits ##############################################\n",
    "\n",
    "def create_sets(X, y):\n",
    "    # Split into training and testing components first\n",
    "    from sklearn.cross_validation import train_test_split, ShuffleSplit\n",
    "    \n",
    "    # Set the number of training points\n",
    "    num_train = int(round(0.80*len(X)))\n",
    "    \n",
    "    # Set the number of testing points\n",
    "    num_test = X.shape[0] - num_train\n",
    "    \n",
    "    # Shuffle and split the dataset into the number of training and testing points above\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = num_train, random_state=123458)\n",
    "    \n",
    "    # Show the results of the split\n",
    "    print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "    print \"Testing set has {} samples.\".format(X_test.shape[0])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "##############################################   Model   Fitting   ##############################################\n",
    "##############################################   Model   Fitting   ##############################################\n",
    "\n",
    "# Using GridSearch CV, we fine tune the model.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "def fit_model(X, y, n_estimators = 1000, min_samples_leaf = 1, min_samples_split =2):\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20)\n",
    "    regressor = GradientBoostingRegressor(n_estimators=n_estimators,min_samples_leaf = 1, \n",
    "                                          min_samples_split =2,random_state=102345)\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'learning_rate': [0.01, 0.02, 0.05, 0.1], # 'n_estimators': [100, 500, 1000],\n",
    "              'max_depth': [2, 3, 4, 6], 'min_samples_leaf':  [2,3,5,9,17]}\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "    # Create the grid search object\n",
    "    grid = GridSearchCV(regressor, params, cv=cv_sets, scoring = scoring_fnc)#, verbose=10)\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "    # Print the optimal model after fitting the data\n",
    "    print 'The cross-validation scores = {:.2f}'.format(grid.best_score_)\n",
    "    print grid.best_estimator_\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make dummies for categorical features.\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'GarageCond' => 'GarageCond_Ex', etc.\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_nans(df):\n",
    "    nan_df = df[pd.isnull(df).any(axis=1)]\n",
    "    for col in nan_df.columns:\n",
    "        tmp = nan_df[col][pd.isnull(nan_df[col])]\n",
    "        if len(tmp) >= 1:\n",
    "            #print \"These features have NULLs to signify the absence of such a feature:\"\n",
    "            print col, len(tmp)\n",
    "            df[col] = df[col].fillna(0.)\n",
    "    print np.shape(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center/> IV. Process and Train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <center> 4.1 WITH REPEAT OUTLIERS\n",
    "\n",
    "## 4.1.1 Preprocessing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage 259\n",
      "Alley 1369\n",
      "MasVnrType 8\n",
      "MasVnrArea 8\n",
      "BsmtQual 37\n",
      "BsmtCond 37\n",
      "BsmtExposure 38\n",
      "BsmtFinType1 37\n",
      "BsmtFinType2 38\n",
      "Electrical 1\n",
      "FireplaceQu 690\n",
      "GarageType 81\n",
      "GarageYrBlt 81\n",
      "GarageFinish 81\n",
      "GarageQual 81\n",
      "GarageCond 81\n",
      "PoolQC 1453\n",
      "Fence 1179\n",
      "MiscFeature 1406\n",
      "(1460, 80)\n",
      "['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'Alley', 'BedroomAbvGr', 'BldgType', 'BsmtCond', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFinType1', 'BsmtFinType2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtQual', 'BsmtUnfSF', 'CentralAir', 'Condition1', 'Condition2', 'Electrical', 'EnclosedPorch', 'ExterCond', 'ExterQual', 'Exterior1st', 'Exterior2nd', 'Fence', 'FireplaceQu', 'Fireplaces', 'Foundation', 'FullBath', 'Functional', 'GarageArea', 'GarageCars', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'GarageYrBlt', 'GrLivArea', 'HalfBath', 'Heating', 'HeatingQC', 'HouseStyle', 'KitchenAbvGr', 'KitchenQual', 'LandContour', 'LandSlope', 'LotArea', 'LotConfig', 'LotFrontage', 'LotShape', 'LowQualFinSF', 'MSSubClass', 'MSZoning', 'MasVnrArea', 'MasVnrType', 'MiscFeature', 'MiscVal', 'MoSold', 'Neighborhood', 'OpenPorchSF', 'OverallCond', 'OverallQual', 'PavedDrive', 'PoolArea', 'PoolQC', 'RoofMatl', 'RoofStyle', 'SaleCondition', 'SaleType', 'ScreenPorch', 'Street', 'TotRmsAbvGrd', 'TotalBsmtSF', 'Utilities', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "data = remove_nans(data)\n",
    "y_all =  data['SalePrice'] #in the log\n",
    "X_all =  data[data.columns[:-1]]\n",
    "print sorted(X_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (304 total features):\n",
      "['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'Alley_0.0', 'Alley_Grvl', 'Alley_Pave', 'BedroomAbvGr', 'BldgType_1Fam', 'BldgType_2fmCon', 'BldgType_Duplex', 'BldgType_Twnhs', 'BldgType_TwnhsE', 'BsmtCond_0.0', 'BsmtCond_Fa', 'BsmtCond_Gd', 'BsmtCond_Po', 'BsmtCond_TA', 'BsmtExposure_0.0', 'BsmtExposure_Av', 'BsmtExposure_Gd', 'BsmtExposure_Mn', 'BsmtExposure_No', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFinType1_0.0', 'BsmtFinType1_ALQ', 'BsmtFinType1_BLQ', 'BsmtFinType1_GLQ', 'BsmtFinType1_LwQ', 'BsmtFinType1_Rec', 'BsmtFinType1_Unf', 'BsmtFinType2_0.0', 'BsmtFinType2_ALQ', 'BsmtFinType2_BLQ', 'BsmtFinType2_GLQ', 'BsmtFinType2_LwQ', 'BsmtFinType2_Rec', 'BsmtFinType2_Unf', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtQual_0.0', 'BsmtQual_Ex', 'BsmtQual_Fa', 'BsmtQual_Gd', 'BsmtQual_TA', 'BsmtUnfSF', 'CentralAir_N', 'CentralAir_Y', 'Condition1_Artery', 'Condition1_Feedr', 'Condition1_Norm', 'Condition1_PosA', 'Condition1_PosN', 'Condition1_RRAe', 'Condition1_RRAn', 'Condition1_RRNe', 'Condition1_RRNn', 'Condition2_Artery', 'Condition2_Feedr', 'Condition2_Norm', 'Condition2_PosA', 'Condition2_PosN', 'Condition2_RRAe', 'Condition2_RRAn', 'Condition2_RRNn', 'Electrical_0.0', 'Electrical_FuseA', 'Electrical_FuseF', 'Electrical_FuseP', 'Electrical_Mix', 'Electrical_SBrkr', 'EnclosedPorch', 'ExterCond_Ex', 'ExterCond_Fa', 'ExterCond_Gd', 'ExterCond_Po', 'ExterCond_TA', 'ExterQual_Ex', 'ExterQual_Fa', 'ExterQual_Gd', 'ExterQual_TA', 'Exterior1st_AsbShng', 'Exterior1st_AsphShn', 'Exterior1st_BrkComm', 'Exterior1st_BrkFace', 'Exterior1st_CBlock', 'Exterior1st_CemntBd', 'Exterior1st_HdBoard', 'Exterior1st_ImStucc', 'Exterior1st_MetalSd', 'Exterior1st_Plywood', 'Exterior1st_Stone', 'Exterior1st_Stucco', 'Exterior1st_VinylSd', 'Exterior1st_Wd Sdng', 'Exterior1st_WdShing', 'Exterior2nd_AsbShng', 'Exterior2nd_AsphShn', 'Exterior2nd_Brk Cmn', 'Exterior2nd_BrkFace', 'Exterior2nd_CBlock', 'Exterior2nd_CmentBd', 'Exterior2nd_HdBoard', 'Exterior2nd_ImStucc', 'Exterior2nd_MetalSd', 'Exterior2nd_Other', 'Exterior2nd_Plywood', 'Exterior2nd_Stone', 'Exterior2nd_Stucco', 'Exterior2nd_VinylSd', 'Exterior2nd_Wd Sdng', 'Exterior2nd_Wd Shng', 'Fence_0.0', 'Fence_GdPrv', 'Fence_GdWo', 'Fence_MnPrv', 'Fence_MnWw', 'FireplaceQu_0.0', 'FireplaceQu_Ex', 'FireplaceQu_Fa', 'FireplaceQu_Gd', 'FireplaceQu_Po', 'FireplaceQu_TA', 'Fireplaces', 'Foundation_BrkTil', 'Foundation_CBlock', 'Foundation_PConc', 'Foundation_Slab', 'Foundation_Stone', 'Foundation_Wood', 'FullBath', 'Functional_Maj1', 'Functional_Maj2', 'Functional_Min1', 'Functional_Min2', 'Functional_Mod', 'Functional_Sev', 'Functional_Typ', 'GarageArea', 'GarageCars', 'GarageCond_0.0', 'GarageCond_Ex', 'GarageCond_Fa', 'GarageCond_Gd', 'GarageCond_Po', 'GarageCond_TA', 'GarageFinish_0.0', 'GarageFinish_Fin', 'GarageFinish_RFn', 'GarageFinish_Unf', 'GarageQual_0.0', 'GarageQual_Ex', 'GarageQual_Fa', 'GarageQual_Gd', 'GarageQual_Po', 'GarageQual_TA', 'GarageType_0.0', 'GarageType_2Types', 'GarageType_Attchd', 'GarageType_Basment', 'GarageType_BuiltIn', 'GarageType_CarPort', 'GarageType_Detchd', 'GarageYrBlt', 'GrLivArea', 'HalfBath', 'HeatingQC_Ex', 'HeatingQC_Fa', 'HeatingQC_Gd', 'HeatingQC_Po', 'HeatingQC_TA', 'Heating_Floor', 'Heating_GasA', 'Heating_GasW', 'Heating_Grav', 'Heating_OthW', 'Heating_Wall', 'HouseStyle_1.5Fin', 'HouseStyle_1.5Unf', 'HouseStyle_1Story', 'HouseStyle_2.5Fin', 'HouseStyle_2.5Unf', 'HouseStyle_2Story', 'HouseStyle_SFoyer', 'HouseStyle_SLvl', 'KitchenAbvGr', 'KitchenQual_Ex', 'KitchenQual_Fa', 'KitchenQual_Gd', 'KitchenQual_TA', 'LandContour_Bnk', 'LandContour_HLS', 'LandContour_Low', 'LandContour_Lvl', 'LandSlope_Gtl', 'LandSlope_Mod', 'LandSlope_Sev', 'LotArea', 'LotConfig_Corner', 'LotConfig_CulDSac', 'LotConfig_FR2', 'LotConfig_FR3', 'LotConfig_Inside', 'LotFrontage', 'LotShape_IR1', 'LotShape_IR2', 'LotShape_IR3', 'LotShape_Reg', 'LowQualFinSF', 'MSSubClass', 'MSZoning_C (all)', 'MSZoning_FV', 'MSZoning_RH', 'MSZoning_RL', 'MSZoning_RM', 'MasVnrArea', 'MasVnrType_0.0', 'MasVnrType_BrkCmn', 'MasVnrType_BrkFace', 'MasVnrType_None', 'MasVnrType_Stone', 'MiscFeature_0.0', 'MiscFeature_Gar2', 'MiscFeature_Othr', 'MiscFeature_Shed', 'MiscFeature_TenC', 'MiscVal', 'MoSold', 'Neighborhood_Blmngtn', 'Neighborhood_Blueste', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_ClearCr', 'Neighborhood_CollgCr', 'Neighborhood_Crawfor', 'Neighborhood_Edwards', 'Neighborhood_Gilbert', 'Neighborhood_IDOTRR', 'Neighborhood_MeadowV', 'Neighborhood_Mitchel', 'Neighborhood_NAmes', 'Neighborhood_NPkVill', 'Neighborhood_NWAmes', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown', 'Neighborhood_SWISU', 'Neighborhood_Sawyer', 'Neighborhood_SawyerW', 'Neighborhood_Somerst', 'Neighborhood_StoneBr', 'Neighborhood_Timber', 'Neighborhood_Veenker', 'OpenPorchSF', 'OverallCond', 'OverallQual', 'PavedDrive_N', 'PavedDrive_P', 'PavedDrive_Y', 'PoolArea', 'PoolQC_0.0', 'PoolQC_Ex', 'PoolQC_Fa', 'PoolQC_Gd', 'RoofMatl_ClyTile', 'RoofMatl_CompShg', 'RoofMatl_Membran', 'RoofMatl_Metal', 'RoofMatl_Roll', 'RoofMatl_Tar&Grv', 'RoofMatl_WdShake', 'RoofMatl_WdShngl', 'RoofStyle_Flat', 'RoofStyle_Gable', 'RoofStyle_Gambrel', 'RoofStyle_Hip', 'RoofStyle_Mansard', 'RoofStyle_Shed', 'SaleCondition_Abnorml', 'SaleCondition_AdjLand', 'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal', 'SaleCondition_Partial', 'SaleType_COD', 'SaleType_CWD', 'SaleType_Con', 'SaleType_ConLD', 'SaleType_ConLI', 'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD', 'ScreenPorch', 'Street_Grvl', 'Street_Pave', 'TotRmsAbvGrd', 'TotalBsmtSF', 'Utilities_AllPub', 'Utilities_NoSeWa', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold']\n",
      "(1460, 304)\n"
     ]
    }
   ],
   "source": [
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(sorted(X_all.columns)))\n",
    "print np.shape(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Feature size ballooned to 304."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 Investigate learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import visuals as vs\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "sns.set_style(\"white\")\n",
    "vs.ModelLearning(X_all, y_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vs.ModelComplexity(X_all, y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### We likely need 1000$^{ish}$ estimators. As before, we use the usual 80-20 split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 Begin training the full sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = create_sets(X_all, y_all)\n",
    "reg = fit_model(X_train, y_train, n_estimators=1000, min_samples_leaf = 1, min_samples_split = 10)\n",
    "pred = reg.predict(X_test)\n",
    "    \n",
    "print 'The R$^2$ = {:.2f}'.format(r2_score(pred, y_test))\n",
    "print 'The  RMSE = {:.2e}.'.format(mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.4 Visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "sns.set_style({\"xtick.direction\": \"in\",\"ytick.direction\": \"in\"})\n",
    "plt.scatter(y_test/1e5, pred/1e5, alpha = 0.5, s = 1000*np.abs(y_test-pred)/y_test, color = 'red')\n",
    "plt.xlabel(r\"True Sale Price [$\\times 10^{5} $ USD]\", fontsize = 30);\n",
    "plt.ylabel(r\"Predicted [$\\times 10^{5} $ USD]\", fontsize = 30);\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "plt.plot(np.arange(0,10, 1), np.arange(0,10, 1), 'k--')\n",
    "plt.tick_params('both', length=8, width=2, which='minor');\n",
    "plt.tick_params('both', length=12, width=3, which='major');\n",
    "plt.xlim(min([min(y_test/1e5), min(pred/1e5)])-0.5, max([max(y_test/1e5), max(pred)/1e5])+0.5)\n",
    "plt.ylim(min([min(y_test/1e5), min(pred/1e5)])-0.5, max([max(y_test/1e5), max(pred)/1e5])+0.5)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig(\"FinalModel_linear_all.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = (y_test - pred)/y_test*100.\n",
    "sns.distplot(diff, bins=20, color='g', hist_kws={\"histtype\": \"stepfilled\", \"linewidth\": 4, \n",
    "                                                    \"alpha\": 0.60, \"color\": \"pink\"});\n",
    "plt.xlabel(r\"$\\frac{y_{test} - \\mathrm{pred} }{y_{test}}$\" + r\"[$ \\times $ 100%]\", fontsize = 30);\n",
    "plt.ylabel(r\"Frequency\", fontsize = 30);\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "\n",
    "plt.tick_params('both', length=8, width=2, which='minor');\n",
    "plt.tick_params('both', length=12, width=3, which='major');\n",
    "plt.savefig('FinalDiffDist_linear_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SECONDARY AXIS WITH COLOR BAR\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "fig = plt.figure()#, figsize=(6,6))\n",
    "gs = grd.GridSpec(2, 1, height_ratios=[1,15], width_ratios=[20,1], wspace=0.1)\n",
    "\n",
    "#Primary plot\n",
    "ax1 = plt.subplot(gs[1])\n",
    "ax1.hist(y_test, color = [\"black\"], alpha=0.15)\n",
    "\n",
    "plt.xlabel(r'House Sale Price [USD]', size=30)\n",
    "plt.ylabel('Counts', size = 30)\n",
    "\n",
    "\n",
    "#Secondary AXIS\n",
    "ax2 = ax1.twinx()\n",
    "ax2.xaxis.set_minor_locator(minorLocatorx)\n",
    "ax2.yaxis.set_minor_locator(minorLocatory)\n",
    "\n",
    "ax2.scatter(y_test, diff,  edgecolor= 'none', s=50, c='red', alpha=0.5)\n",
    "ax2.set_ylabel(r\"$\\frac{y_{test} - pred }{y_{test}}$\" + r\" [$\\times 100\\% $ ]\", fontsize = 30);\n",
    "\n",
    "plt.plot([0, 1e8], [2*np.std(np.abs(diff)),2*np.std(np.abs(diff))], color = 'green', linestyle = '--')\n",
    "plt.plot([0, 1e8], [-2*np.std(np.abs(diff)),12*np.std(np.abs(diff))], color = 'green', linestyle = '--')\n",
    "plt.ylim(min(diff)-5, max(np.abs(diff))+5)\n",
    "plt.xlim(min(y_test), max(y_test));\n",
    "plt.savefig('Residuals_linear_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"The Kaggle log-RMSE is now {:.4f}\".format(np.sqrt(np.sum((np.log(y_test +1) - np.log(pred+1))**2)/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> 4.2 Removing outliers NOW!\n",
    "\n",
    "### Using [Tukey's Method for identfying outliers](http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/): An *outlier step* is calculated as 1.5 times the interquartile range (IQR). A data point with a feature that is beyond an outlier step outside of the IQR for that feature is considered abnormal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Define function that removes REPEAT outliers. \n",
    "\n",
    "Consider as outliers only for those which are continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Try to remove outliers\n",
    "# For each feature in out_columns find the data points with extreme high or low values\n",
    "def remove_outliers(df):\n",
    "    outliers  = []\n",
    "    out_columns = ['LotArea', 'MasVnrArea', 'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', \n",
    "                   'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'SalePrice', '1stFlrSF', \n",
    "                   \"2ndFlrSF\", \"ScreenPorch\", \"PoolArea\", '3SsnPorch', \"MiscVal\", \"EnclosedPorch\",\n",
    "                   'BsmtFinSF2','LowQualFinSF', \"BsmtUnfSF\", 'LotFrontage']\n",
    "    for feature in out_columns:\n",
    "        \n",
    "        # Calculate Q1 (25th percentile of the data) for the given feature\n",
    "        Q1 = np.percentile(df[feature], 25)\n",
    "        \n",
    "        # Calculate Q3 (75th percentile of the data) for the given feature\n",
    "        Q3 = np.percentile(df[feature], 75)\n",
    "        \n",
    "        # Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "        step = 1.5*(Q3-Q1)\n",
    "        \n",
    "        outliers = list(outliers + df[~((df[feature] >= Q1 - step) & \\\n",
    "                                                  (df[feature] <= Q3 + step))].index.tolist())\n",
    "    \n",
    "    # Select the indices for data points you wish to remove\n",
    "    from collections import Counter\n",
    "    counts = Counter(outliers)\n",
    "    outliers = sorted([value for value, count in counts.items() if count > 1])\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.2 Start from a clean slate and then preprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Start from a clean slate.\n",
    "data = pd.read_csv('train.csv')\n",
    "data = data.drop(['Id'], axis=1)\n",
    "\n",
    "# Remove NaNs\n",
    "data_all = remove_nans(data)\n",
    "\n",
    "\n",
    "# Dummies\n",
    "data = preprocess_features(data)\n",
    "print data.shape\n",
    "\n",
    "\n",
    "# Remove Outliers\n",
    "outliers = remove_outliers(data)\n",
    "good_data = data.drop(data.index[outliers]).reset_index(drop = True)\n",
    "good_data_X = good_data[good_data.columns[:-1]]\n",
    "good_data_y =  good_data[good_data.columns[-1]]\n",
    "print \"The dimensions of the data without outliers now is {}\".format(np.shape(good_data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.3 Begin training without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_good, X_test_good, y_train_good, y_test_good = create_sets(good_data_X, good_data_y)\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "reg_good = fit_model(X_train_good, y_train_good, n_estimators=1000, min_samples_leaf = 1, min_samples_split = 10)\n",
    "end = time()\n",
    "print \"Trained model in {:.4f} seconds\".format(end-start)\n",
    "\n",
    "start = time()\n",
    "pred_good = reg_good.predict(X_test_good)\n",
    "end = time()\n",
    "print \"Model made predictions in {:.4f} seconds\".format(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.4 Evaluate, validate and visualize results.\n",
    "\n",
    "There are 247 examples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'The R$^2$ = {:.2f}'.format(r2_score(pred_good, y_test_good))\n",
    "print 'The  RMSE = {:.2e}.'.format(mean_squared_error(pred_good, y_test_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "sns.set_style({\"xtick.direction\": \"in\",\"ytick.direction\": \"in\"})\n",
    "plt.scatter(y_test_good/1e5, pred_good/1e5, alpha = 0.5, s = 1000*np.abs(y_test_good-pred_good)/y_test_good, color = 'red')\n",
    "plt.xlabel(r\"True Sale Price [$\\times 10^{5} $ USD]\", fontsize = 30);\n",
    "plt.ylabel(r\"Predicted [$\\times 10^{5} $ USD]\", fontsize = 30);\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "plt.plot(np.arange(0,10, 1), np.arange(0,10, 1), 'k--')\n",
    "plt.tick_params('both', length=8, width=2, which='minor');\n",
    "plt.tick_params('both', length=12, width=3, which='major');\n",
    "plt.xlim(min([min(y_test_good), min(pred)])/1e5, max([max(y_test_good)-0.5, max(pred_good)])/1e5+0.5)\n",
    "plt.ylim(min([min(y_test_good), min(pred)])/1e5, max([max(y_test_good)-0.5, max(pred_good)])/1e5+0.5)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig(\"FinalModel_linear_all.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_good = (y_test_good - pred_good)/y_test_good*100.\n",
    "sns.distplot(diff_good, bins=20, color='g', hist_kws={\"histtype\": \"stepfilled\", \"linewidth\": 4, \n",
    "                                                    \"alpha\": 0.60, \"color\": \"pink\"});\n",
    "plt.xlabel(r\"$\\frac{y_{test} - \\mathrm{pred} }{y_{test}}$\" + r\"[$ \\times $ 100%]\", fontsize = 30);\n",
    "plt.ylabel(r\"Frequency\", fontsize = 30);\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "\n",
    "plt.tick_params('both', length=8, width=2, which='minor');\n",
    "plt.tick_params('both', length=12, width=3, which='major');\n",
    "plt.savefig('FinalDiffDist_linear_all.pdf')\n",
    "\n",
    "print \"The mean is {:.2f} and stdev of {:.2f}\".format(np.mean(diff_good), np.std(diff_good))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the model predict outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_out = data.iloc[outliers, :]\n",
    "X_out = test_data_out[test_data_out.columns[:-1]]\n",
    "y_out = test_data_out[test_data_out.columns[-1]]\n",
    "X_test_data_out_good = X_out.append(X_test_good, ignore_index=True)\n",
    "y_test_data_out_good = y_out.append(y_test_good)\n",
    "\n",
    "print 'The outliers and test set combined has {} examples'.format(len(X_test_data_out_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Predict the outliers\n",
    "pred_out = reg_good.predict(X_out)\n",
    "print 'The R$^2$ = {:.2f}'.format(r2_score(pred_out, y_out))\n",
    "print 'The  RMSE = {:.2e}.'.format(mean_squared_error(pred_out, y_out))\n",
    "\n",
    "## Predict the test and outliers\n",
    "pred_out_good = reg_good.predict(X_test_data_out_good)\n",
    "print 'The R$^2$ = {:.2f}'.format(r2_score(pred_out_good, y_test_data_out_good))\n",
    "print 'The  RMSE = {:.2e}.'.format(mean_squared_error(pred_out_good, y_test_data_out_good))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "sns.set_style({\"xtick.direction\": \"in\",\"ytick.direction\": \"in\"})\n",
    "plt.scatter(y_test_data_out_good/1e5, pred_out_good/1e5, alpha = 0.5, \n",
    "            s = 1000*np.abs(y_test_data_out_good-pred_out_good)/y_test_data_out_good, color = 'blue',\n",
    "           label ='Test Set')\n",
    "plt.scatter(y_out/1e5, pred_out/1e5, alpha = 0.5, s = 1000*np.abs(y_out-pred_out)/y_out, color = 'red',\n",
    "           label ='Outliers Set')\n",
    "plt.xlabel(r\"True Sale Price [$\\times 10^{5} $ USD]\", fontsize = 30);\n",
    "plt.ylabel(r\"Predicted [$\\times 10^{5} $ USD]\", fontsize = 30);\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "plt.plot(np.arange(0,10, 1), np.arange(0,10, 1), 'k--')\n",
    "plt.tick_params('both', length=8, width=2, which='minor');\n",
    "plt.tick_params('both', length=12, width=3, which='major');\n",
    "plt.xlim(min([min(y_out), min(pred_out)])/1e5-0.5, max([max(y_out), max(pred_out)])/1e5+0.5)\n",
    "plt.ylim(min([min(y_out), min(pred_out)])/1e5-0.5, max([max(y_out), max(pred_out)])/1e5+0.5)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(loc = 'lower right', fontsize=25)\n",
    "plt.savefig(\"FinalModel_linear_out.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Kaggle\\'s log-RMSE score is {:.6f}'.\\\n",
    "format(np.sqrt(np.sum((np.log(y_test_data_out_good +1) - np.log(pred_out_good+1))**2)/len(y_test_data_out_good)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_out = (y_test_data_out_good - pred_out_good)/y_test_data_out_good*100.\n",
    "sns.distplot(diff_good, bins=20, color='g', hist_kws={\"histtype\": \"stepfilled\", \"linewidth\": 4, \n",
    "                                                    \"alpha\": 0.60, \"color\": \"pink\"});\n",
    "plt.xlabel(r\"$\\frac{y_{test} - \\mathrm{pred} }{y_{test}}$\" + r\"[$ \\times $ 100%]\", fontsize = 30);\n",
    "plt.ylabel(r\"Frequency\", fontsize = 30);\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "\n",
    "plt.tick_params('both', length=8, width=2, which='minor');\n",
    "plt.tick_params('both', length=12, width=3, which='major');\n",
    "plt.savefig('FinalDiffDist_linear_out.pdf')\n",
    "\n",
    "print \"The mean is {:.2f} and stdev of {:.2f}\".format(np.mean(diff_out), np.std(diff_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now testing on the test.csv set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load\n",
    "test = pd.read_csv('test.csv')\n",
    "## Remove NaNs\n",
    "data = remove_nans(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
